/* **********************************************************
 * Copyright (c) 2015-2018 Google, Inc.  All rights reserved.
 * **********************************************************/

/*
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are met:
 *
 * * Redistributions of source code must retain the above copyright notice,
 *   this list of conditions and the following disclaimer.
 *
 * * Redistributions in binary form must reproduce the above copyright notice,
 *   this list of conditions and the following disclaimer in the documentation
 *   and/or other materials provided with the distribution.
 *
 * * Neither the name of Google, Inc. nor the names of its contributors may be
 *   used to endorse or promote products derived from this software without
 *   specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED. IN NO EVENT SHALL GOOGLE, INC. OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
 * DAMAGE.
 */

/**
***************************************************************************
***************************************************************************
\page page_drcachesim Cache Simulator

\p drcachesim is a DynamoRIO client that collects memory access traces and
feeds them to either an online or offline tool for analysis.  The default
analysis tool is a CPU cache simulator, while other provided tools compute
metrics such as reuse distance.  The trace collector and simulator support
multiple processes each with multiple threads.  The analysis tool framework
is extensible, supporting the creation of new tools which can operate both
online and offline.

 - \ref sec_drcachesim
 - \ref sec_drcachesim_run
 - \ref sec_drcachesim_tools
 - \ref sec_drcachesim_config_file
 - \ref sec_drcachesim_offline
 - \ref sec_drcachesim_partial
 - \ref sec_drcachesim_sim
 - \ref sec_drcachesim_analyzer
 - \ref sec_drcachesim_phys
 - \ref sec_drcachesim_core
 - \ref sec_drcachesim_extend
 - \ref sec_drcachesim_tracer
 - \ref sec_drcachesim_newtool
 - \ref sec_drcachesim_ops
 - \ref sec_drcachesim_limit
 - \ref sec_drcachesim_cmp

****************************************************************************
\section sec_drcachesim Overview

\p drcachesim consists of two components: a tracer and an analyzer.
The tracer collects a memory access trace from each thread within each
application process.
The analyzer consumes the traces (online or offline) and performs
customized analysis.
It is designed to be extensible, allowing users to easily implement a
simulator for different devices, such as CPU caches, TLBs, page
caches, etc. (see \ref sec_drcachesim_extend), or to build arbitrary trace
analysis tools (see \ref sec_drcachesim_newtool).
The default analyzer simulates the architectural behavior of caching
devices for a target application (or multiple applications).

****************************************************************************
\section sec_drcachesim_run Running the Simulator

To launch \p drcachesim, use the \p -t flag to \p drrun:

\code
$ bin64/drrun -t drcachesim -- /path/to/target/app <args> <for> <app>
\endcode

The target application will be launched under a DynamoRIO tracer
client that gathers all of its memory references and passes them to
the simulator via a pipe.  (See \ref sec_drcachesim_offline for how to dump
a trace for offline analysis.)
Any child processes will be followed into and profiled, with their
memory references passed to the simulator as well.

Here is an example:

\code
$ bin64/drrun -t drcachesim -- ~/test/pi_estimator
Estimation of pi is 3.142425985001098
---- <application exited with code 0> ----
Cache simulation results:
Core #0 (1 thread(s))
  L1I stats:
    Hits:                          258,433
    Misses:                          1,148
    Miss rate:                        0.44%
  L1D stats:
    Hits:                           93,654
    Misses:                          2,624
    Prefetch hits:                     458
    Prefetch misses:                 2,166
    Miss rate:                        2.73%
Core #1 (1 thread(s))
  L1I stats:
    Hits:                            8,895
    Misses:                             99
    Miss rate:                        1.10%
  L1D stats:
    Hits:                            3,448
    Misses:                            156
    Prefetch hits:                      26
    Prefetch misses:                   130
    Miss rate:                        4.33%
Core #2 (1 thread(s))
  L1I stats:
    Hits:                            4,150
    Misses:                            101
    Miss rate:                        2.38%
  L1D stats:
    Hits:                            1,578
    Misses:                            130
    Prefetch hits:                      25
    Prefetch misses:                   105
    Miss rate:                        7.61%
Core #3 (0 thread(s))
LL stats:
    Hits:                            1,414
    Misses:                          2,844
    Prefetch hits:                     824
    Prefetch misses:                 1,577
    Local miss rate:                 66.79%
    Child hits:                    370,667
    Total miss rate:                  0.76%
\endcode

****************************************************************************
\section sec_drcachesim_tools Analysis Tool Suite

In addition to a CPU cache simulator, other analysis tools are available
that operate on memory address traces.  Which tool is used can be selected
with the \p -simulator_type parameter.

To simulate TLB devices instead of caches, pass \p TLB to \p -simulator_type:

\code
$ bin64/drrun -t drcachesim -simulator_type TLB -- ~/test/pi_estimator
Estimation of pi is 3.142425985001098
---- <application exited with code 0> ----
TLB simulation results:
Core #0 (1 thread(s))
  L1I stats:
    Hits:                          252,412
    Misses:                            401
    Miss rate:                        0.16%
  L1D stats:
    Hits:                           87,132
    Misses:                          9,127
    Miss rate:                        9.48%
  LL stats:
    Hits:                            9,315
    Misses:                            213
    Local miss rate:                  2.24%
    Child hits:                    339,544
    Total miss rate:                  0.06%
Core #1 (1 thread(s))
  L1I stats:
    Hits:                            8,709
    Misses:                             20
    Miss rate:                        0.23%
  L1D stats:
    Hits:                            3,544
    Misses:                             55
    Miss rate:                        1.53%
  LL stats:
    Hits:                               15
    Misses:                             60
    Local miss rate:                 80.00%
    Child hits:                     12,253
    Total miss rate:                  0.49%
Core #2 (1 thread(s))
  L1I stats:
    Hits:                            1,622
    Misses:                             21
    Miss rate:                        1.28%
  L1D stats:
    Hits:                              689
    Misses:                             35
    Miss rate:                        4.83%
  LL stats:
    Hits:                                3
    Misses:                             53
    Local miss rate:                 94.64%
    Child hits:                      2,311
    Total miss rate:                  2.24%
Core #3 (0 thread(s))
\endcode

To compute reuse distance metrics:

\code
$ bin64/drrun -t drcachesim -simulator_type reuse_distance -reuse_distance_histogram -- ~/test/pi_estimator
Estimation of pi is 3.142425985001098
---- <application exited with code 0> ----
Reuse distance tool results:
Total accesses: 361486
Unique accesses: 205963
Unique cache lines accessed: 4188

Reuse distance mean: 14.76
Reuse distance median: 1
Reuse distance standard deviation: 109.74
Reuse distance histogram:
Distance       Count  Percent  Cumulative
       0      155523   43.53%   43.53%
       1      108799   30.45%   73.98%
       2       17659    4.94%   78.92%
       3       12417    3.48%   82.40%
       4        9304    2.60%   85.00%
       5        3949    1.11%   86.10%
       6        1747    0.49%   86.59%
       7        3091    0.87%   87.46%
       8        3894    1.09%   88.55%
       9        3047    0.85%   89.40%
      10        1415    0.40%   89.80%
      11        1113    0.31%   90.11%
      12         682    0.19%   90.30%
      13         773    0.22%   90.52%
      14         698    0.20%   90.71%
      15        1167    0.33%   91.04%
      16         971    0.27%   91.31%
      17        1564    0.44%   91.75%
      18        1127    0.32%   92.06%
      19         660    0.18%   92.25%
      20         480    0.13%   92.38%
...
    3642           1    0.00%  100.00%
    3906           1    0.00%  100.00%
    3912           1    0.00%  100.00%

Reuse distance threshold = 100 cache lines
Top 10 frequently referenced cache lines
        cache line:     #references   #distant refs
    0x7fc242632780:        30216,           56
    0x7fc240da8fc0:        27664,            0
    0x7fc240da9000:        18629,            0
    0x7fc242622e80:        17864,           70
    0x7fc242622500:        10976,           29
    0x7fc2426224c0:         9633,           28
    0x7fc242624940:         8865,            6
    0x7fc242622480:         8167,           29
    0x7fc240da8f80:         6660,            0
    0x7fc242622540:         5768,           31
Top 10 distant repeatedly referenced cache lines
        cache line:     #references   #distant refs
    0x7fc24283b140:          293,          104
    0x7fc2417806c0:          353,          100
    0x7fc24144d000:          333,          100
    0x7fc24283a940:          322,           99
    0x7fc2417809c0:          212,           97
    0x7fc241780700:          320,           96
    0x7fc24144d300:          202,           96
    0x7fc241754e40:          319,           95
    0x7fc24144d040:          314,           95
    0x7fc24144be40:          309,           95
\endcode

A reuse time tool is also provided, which counts the total number of memory
accesses (without considering uniqueness) between accesses to the same
address:

\code
$ bin64/drrun -t drcachesim -simulator_type reuse_time -- ~/test/pi_estimator
Estimation of pi is 3.142425985001098
---- <application exited with code 0> ----
Reuse time tool results:
Total accesses: 99944
Total instructions: 259351
Mean reuse time: 479.21
Reuse time histogram:
Distance       Count  Percent  Cumulative
       1       33901   34.99%      34.99%
       2       13646   14.09%      49.08%
       3        6837    7.06%      56.13%
...
   88585           1    0.00%     100.00%
   93953           1    0.00%     100.00%
   94830           1    0.00%     100.00%
\endcode

To simply see the counts of instructions and memory references broken down
by thread use the basic counts tool:

\code
$ bin64/drrun -t drcachesim -simulator_type basic_counts -- ~/test/pi_estimator
Estimation of pi is 3.142425985001098
---- <application exited with code 0> ----
Basic counts tool results:
Total counts:
      267193 total (fetched) instructions
         345 total non-fetched instructions
           0 total prefetches
       67686 total data loads
       22503 total data stores
           3 total threads
         280 total scheduling markers
           0 total transfer markers
           0 total other markers
Thread 247451 counts:
      255009 (fetched) instructions
         345 non-fetched instructions
           0 prefetches
       64453 data loads
       21243 data stores
         258 scheduling markers
           0 transfer markers
           0 other markers
Thread 247453 counts:
        9195 (fetched) instructions
           0 non-fetched instructions
           0 prefetches
        2444 data loads
         937 data stores
          12 scheduling markers
           0 transfer markers
           0 other markers
Thread 247454 counts:
        2989 (fetched) instructions
           0 non-fetched instructions
           0 prefetches
         789 data loads
         323 data stores
          10 scheduling markers
           0 transfer markers
           0 other markers
\endcode

The non-fetched instructions are x86 string loop instructions, where
subsequent iterations do not incur a fetch.  They are included in the trace
as a different type of trace entry to support core simulators in addition
to cache simulators.

The opcode_mix tool uses the non-fetched instruction information along with
the preserved libraries and binaries from the traced execution to gather
more information on each executed instruction than was stored in the trace.
It only supports offline traces, and the \p modules.log file created during
post-processing of the trace must be preserved.  The results are broken
down by the opcodes used in DR's IR, where \p mov is split into a separate
opcode for load and store but both have the same public string "mov":

\code
$ bin64/drrun -t drcachesim -offline -- ~/test/pi_estimator
Estimation of pi is 3.142425985001098
$ bin64/drrun -t drcachesim -simulator_type opcode_mix -indir drmemtrace.*.dir
Opcode mix tool results:
         267271 : total executed instructions
          36432 :       mov
          31075 :       mov
          24715 :       add
          22579 :      test
          22539 :       cmp
          12137 :       lea
          11136 :       jnz
          10568 :     movzx
          10243 :        jz
           9056 :       and
           8064 :       jnz
           7279 :        jz
           5659 :      push
           4528 :       sub
           4357 :       pop
           4001 :       shr
           3427 :      jnbe
           2634 :       mov
           2469 :       shl
           2344 :        jb
           2291 :       ret
           2178 :       xor
           2164 :      call
           2111 :   pcmpeqb
           1472 :    movdqa
...
\endcode

The view tool prints out disassembled instructions in att, intel, arm or DR
format for offline traces. The -skip_refs and -sim_refs flags can be used to
set a start point and end point for the disassembled view. Note that these
flags compute the number of instructions which are skipped or displayed which
is distinct from the number of trace entries.

\code
$ bin64/drrun -t drcachesim -simulator_type view -sim_refs 20 -indir drmemtrace.*.dir
  0x00007f3a5127d870  48 83 ec 48          sub    $0x48, %rsp
  0x00007f3a5127d874  0f 31                rdtsc
  0x00007f3a5127d876  48 c1 e2 20          shl    $0x20, %rdx
  0x00007f3a5127d87a  89 c0                mov    %eax, %eax
  0x00007f3a5127d87c  48 09 c2             or     %rax, %rdx
  0x00007f3a5127d87f  48 8b 05 ea 25 22 00 mov    <rel> 0x00007f3a5149fe70, %rax
  0x00007f3a5127d886  48 89 15 d3 23 22 00 mov    %rdx, <rel> 0x00007f3a5149fc60
  0x00007f3a5127d88d  48 8d 15 dc 25 22 00 lea    <rel> 0x00007f3a5149fe70, %rdx
  0x00007f3a5127d894  49 89 d6             mov    %rdx, %r14
  0x00007f3a5127d897  4c 2b 35 62 27 22 00 sub    <rel> 0x00007f3a514a0000, %r14
  0x00007f3a5127d89e  48 85 c0             test   %rax, %rax
  0x00007f3a5127d8a1  48 89 15 40 31 22 00 mov    %rdx, <rel> 0x00007f3a514a09e8
  0x00007f3a5127d8a8  4c 89 35 29 31 22 00 mov    %r14, <rel> 0x00007f3a514a09d8
  0x00007f3a5127d8af  0f 84 9b 00 00 00    jz     $0x00007f3a5127d950
  0x00007f3a5127d8b5  4c 8d 05 84 27 22 00 lea    <rel> 0x00007f3a514a0040, %r8
  0x00007f3a5127d8bc  49 b9 d8 03 00 80 03 mov    $0x00000003800003d8, %r9
                      00 00 00
  0x00007f3a5127d8c6  48 b9 78 fb ff 7f 03 mov    $0x000000037ffffb78, %rcx
                      00 00 00
  0x00007f3a5127d8d0  48 8d 35 41 31 22 00 lea    <rel> 0x00007f3a514a0a18, %rsi
  0x00007f3a5127d8d7  bf ff ff ff 6f       mov    $0x6fffffff, %edi
  0x00007f3a5127d8dc  41 bb ff fd ff 6f    mov    $0x6ffffdff, %r11d
View tool results:
             20 : total disassembled instructions
\endcode

The top referenced cache lines are displayed by the \p histogram tool:

\code
$ bin64/drrun -t drcachesim -simulator_type histogram -- ~/test/pi_estimator
Estimation of pi is 3.142425985001098
---- <application exited with code 0> ----
Cache line histogram tool results:
icache: 1134 unique cache lines
dcache: 3062 unique cache lines
icache top 10
    0x7facdd013780: 30929
    0x7facdb789fc0: 27664
    0x7facdb78a000: 18629
    0x7facdd003e80: 18176
    0x7facdd003500: 11121
    0x7facdd0034c0: 9763
    0x7facdd005940: 8865
    0x7facdd003480: 8277
    0x7facdb789f80: 6660
    0x7facdd003540: 5888
dcache top 10
    0x7ffcc35e7d80: 4088
    0x7ffcc35e7d40: 3497
    0x7ffcc35e7e00: 3478
    0x7ffcc35e7f40: 2919
    0x7ffcc35e7dc0: 2837
    0x7facdbe2e980: 2452
    0x7facdbe2ec80: 2273
    0x7ffcc35e7e80: 2194
    0x7facdb6625c0: 2016
    0x7ffcc35e7e40: 1997
\endcode

****************************************************************************
\section sec_drcachesim_config_file Configuration File

\p drcachesim supports reconfigurable cache hierarchies defined in
a configuration file. The configuration file is a text file with the following
formatting rules.

- A comment starts with two slashes followed by one or more spaces. Anything
after the '// ' until the end of the line is considered a comment and ignored.
- A parameter's name and its value are listed consecutively with white space
(spaces, tabs, or a new line) between them.
- Parameters must be separated by white space. Including one parameter per line
helps keep the configuration file more human-readable.
- A cache's parameters must be enclosed inside braces and preceded by the
cache's user-chosen unique name.
- Parameters can be listed in any order.
- Parameters not included in the configuration file take their default values.
- String values must not be enclosed in quotations.

Supported common parameters and their value types (each of these parameters
sets the corresponding option with the same name described in \ref sec_drcachesim_ops):
- num_cores \<unsigned int\>
- line_size \<unsigned int\>
- skip_refs \<unsigned int\>
- warmup_refs \<unsigned int\>
- warmup_fraction \<float in [0,1]\>
- sim_refs \<unsigned int\>
- cpu_scheduling \<bool\>
- verbose \<unsigned int\>

Supported cache parameters and their value types:
- type \<string, one of "instruction", "data", or "unified"\>
- core \<unsigned int in [0, num_cores)\>
- size \<unsigned int, power of 2\>
- assoc \<unsigned int, power of 2\>
- inclusive \<bool\>
- parent \<string\>
- replace_policy \<string, one of "LRU", "LFU", or "FIFO"\>
- prefetcher \<string, one of "nextline" or "none"\>
- miss_file \<string\>

Example:
\code
// Configuration for a single-core CPU.

// Common params.
num_cores       1
line_size       64
cpu_scheduling  true
sim_refs        8888888
warmup_fraction 0.8

// Cache params.
P0L1I {                        // P0 L1 instruction cache
  type            instruction
  core            0
  size            65536        // 64K
  assoc           8
  parent          P0L2
  replace_policy  LRU
}
P0L1D {                        // P0 L1 data cache
  type            data
  core            0
  size            65536        // 64K
  assoc           8
  parent          P0L2
  replace_policy  LRU
}
P0L2 {                         // P0 L2 unified cache
  size            512K
  assoc           16
  inclusive       true
  parent          LLC
  replace_policy  LRU
}
LLC {                          // LLC
  size            1M
  assoc           16
  inclusive       true
  parent          mem
  replace_policy  LRU
  miss_file       misses.txt
}
\endcode

****************************************************************************
\section sec_drcachesim_offline Offline Traces and Analysis

To dump a trace for future offline analysis, use the \p offline parameter:
\code
$ bin64/drrun -t drcachesim -offline -- /path/to/target/app <args> <for> <app>
\endcode

The collected traces will be dumped into a newly created directory,
which can be passed to drcachesim for offline cache simulation with the \p
-indir option:
\code
$ bin64/drrun -t drcachesim -indir drmemtrace.app.pid.xxxx.dir/
\endcode

The direct results of the \p -offline run are raw, compacted files, stored
in a \p raw subdirectory of the \p drmemtrace.app.pid.xxxx.dir directory.
The \p -indir option both converts the data to a canonical trace form and
passes the resulting data to the cache simulator.  The canonical trace data
is stored by \p -indir in a file named \p drmemtrace.trace inside the \p
drmemtrace.app.pid.xxxx.dir/ directory.  Future runs can point directly at
this file using the \p -infile option:
\code
$ bin64/drrun -t drcachesim -infile drmemtrace.app.pid.xxxx.dir/drmemtrace.trace
\endcode

The \p -infile option supports reading a gzipped trace file, allowing
compression of the \p drmemtrace.trace file to save space:
\code
$ gzip drmemtrace.app.pid.xxxx.dir/drmemtrace.trace
$ bin64/drrun -t drcachesim -infile drmemtrace.app.pid.xxxx.dir/drmemtrace.trace.gz
\endcode

The same analysis tools used online are available for offline: the trace
format is identical.

****************************************************************************
\section sec_drcachesim_partial Tracing a Subset of Execution

While the cache simulator supports skipping references, for large
applications the overhead of the tracing itself is too high to conveniently
trace the entire execution.  There are several methods of tracing only
during a desired window of execution.

The \p -trace_after_instrs option delays tracing by the specified number of
dynamic instruction executions.  This can be used to skip initialization
and arrive at the desired starting point.  The trace's length can also be
limited by the \p -exit_after_tracing option.

If the application can be modified, it can be linked with the \p drcachesim
tracer and use DynamoRIO's start/stop API routines dr_app_setup_and_start()
and dr_app_stop_and_cleanup() to delimit the desired trace region.  As an
example, see <a
href="https://github.com/DynamoRIO/dynamorio/blob/master/clients/drcachesim/tests/burst_static.cpp">our
burst_static test application</a>.

****************************************************************************
\section sec_drcachesim_sim Simulator Details

Generally, the simulator is able to be extended to model a variety of
caching devices.  Currently, CPU caches and TLBs are implemented.  The type of
device to simulate can be specified by the parameter
"-simulator_type" (see \ref sec_drcachesim_ops).

The CPU cache simulator models a configurable number of cores,
each with an L1 data cache and an L1 instruction cache.
Currently there is a single shared L2 unified cache, but we would like to
extend support to arbitrary cache hierarchies (see \ref sec_drcachesim_limit).
The cache line size and each cache's total size and associativity are
user-specified (see \ref sec_drcachesim_ops).

The TLB simulator models a configurable number of cores, each with an
L1 instruction TLB, an L1 data TLB, and an L2 unified TLB.  Each TLB's
entry number and associativity, and the virtual/physical page size,
are user-specified (see \ref sec_drcachesim_ops).

Neither simulator has a simple way to know which core any particular thread
executed on for each of its instructions.  The tracer records which core a
thread is on each time it writes out a full trace buffer, giving an
approximation of the actual scheduling (at the granularity of the trace
buffer size).  By default, these cache and TLB simulators ignore that
information and schedule threads to simulated cores in a static round-robin
fashion with load balancing to fill in gaps with new threads after threads
exit.  The option "-cpu_scheduling" (see \ref sec_drcachesim_ops) can be
used to instead map each physical cpu to a simulated core and use the
recorded cpu that each segment of thread execution occurred on to schedule
execution in a manner that more closely resembles the traced execution on
the physical machine.  Below is an example of the output using this option
running an application with many threads on a pysical machine with 8 cpus.
The 8 cpus are mapped to the 4 simulated cores:

\code
$ bin64/drrun -t drcachesim -cpu_scheduling -- ~/test/pi_estimator 20
Estimation of pi is 3.141592653798125
<Stopping application /home/bruening/dr/test/threadsig (213517)>
---- <application exited with code 0> ----
Cache simulation results:
Core #0 (2 traced CPU(s): #2, #5)
  L1I stats:
    Hits:                        2,756,429
    Misses:                          1,190
    Miss rate:                        0.04%
  L1D stats:
    Hits:                        1,747,822
    Misses:                         13,511
    Prefetch hits:                   2,354
    Prefetch misses:                11,157
    Miss rate:                        0.77%
Core #1 (2 traced CPU(s): #4, #0)
  L1I stats:
    Hits:                          472,948
    Misses:                            299
    Miss rate:                        0.06%
  L1D stats:
    Hits:                          895,099
    Misses:                          1,224
    Prefetch hits:                     253
    Prefetch misses:                   971
    Miss rate:                        0.14%
Core #2 (2 traced CPU(s): #1, #7)
  L1I stats:
    Hits:                          448,581
    Misses:                            649
    Miss rate:                        0.14%
  L1D stats:
    Hits:                          811,483
    Misses:                          1,723
    Prefetch hits:                     378
    Prefetch misses:                 1,345
    Miss rate:                        0.21%
Core #3 (2 traced CPU(s): #6, #3)
  L1I stats:
    Hits:                          275,192
    Misses:                            154
    Miss rate:                        0.06%
  L1D stats:
    Hits:                          522,655
    Misses:                            850
    Prefetch hits:                     173
    Prefetch misses:                   677
    Miss rate:                        0.16%
LL stats:
    Hits:                           12,491
    Misses:                          7,109
    Prefetch hits:                   8,922
    Prefetch misses:                 5,228
    Local miss rate:                 36.27%
    Child hits:                  7,933,367
    Total miss rate:                  0.09%
\endcode

The memory access traces contain some optimizations that combine references
for one basic block together.  This may result in not considering some
thread interleavings that could occur natively.  There are no other
disruptions to thread ordering, however, and the application runs with all
of its threads concurrently just like it would natively (although slower).

Once every process has exited, the simulator prints cache miss statistics
for each cache to stderr.  The simulator is designed to be extensible,
allowing for different cache studies to be carried out: see \ref
sec_drcachesim_extend.

For L2 caching devices, the L1 caching devices are considered its _children_.
Two separate miss rates are computed, one (the "Local miss rate") considering
just requests that reach L2 while the other (the "Total miss rate")
includes the child hits.

For memory requests that cross blocks, each block touched is
considered separately, resulting in separate hit and miss statistics.  This
can be changed by implementing a custom statistics gatherer (see \ref
sec_drcachesim_extend).

Software and hardware prefetches are combined in the prefetch hit and miss
statistics, which are reported separately from regular loads and stores.
To isolate software prefetch statistics, disable the hardware prefetcher by
running with "-data_prefetcher none" (see \ref sec_drcachesim_ops).
While misses from software prefetches are included in cache miss files,
misses from hardware prefetches are not.


****************************************************************************
\section sec_drcachesim_analyzer Cache Miss Analyzer

The cache simulator can be used to analyze the stream of last-level cache (LLC)
miss addresses. This can be useful when looking for patterns that can be utilized
in software prefetching. The current analyzer can only identify simple stride
patterns, but it can be extended to search for more complex patterns.
To invoke the miss analyzer, pass \p miss_analyzer to the \p -simulator_type
parameter. To write the prefetching hints to a file use the \p -LL_miss_file
parameter to specify the file's path and name.

For example, to run the analyzer on a benchmark called "my_benchmark" and store
the prefetching recommendations in a file called "rec.csv", run the following:

\code
$ bin64/drrun -t drcachesim -simulator_type miss_analyzer -LL_miss_file rec.csv -- my_benchmark
\endcode


****************************************************************************
\section sec_drcachesim_phys Physical Addresses

The memory access tracing client gathers virtual addresses.  On Linux, if
the kernel allows user-mode applications access to the \p
/proc/self/pagemap file, physical addresses may be used instead.  This can
be requested via the \p -use_physical runtime option (see \ref
sec_drcachesim_ops).  This works on current kernels but is expected to stop
working from user mode on future kernels due to recent security changes
(see
http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=ab676b7d6fbf4b294bf198fb27ade5b0e865c7ce).

****************************************************************************
\section sec_drcachesim_core Core Simulation Support

The \p drcachesim trace format includes information intended for use by
core simulators as well as pure cache simulators.  For traces that are not
filtered by an online first-level cache, each data reference is preceded by
the instruction fetch entry for the instruction that issued the data
request.  Additionally, on x86, string loop
instructions involve a single insruction fetch followed by a loop of loads
and/or stores.  A \p drcachesim trace includes a special "no-fetch"
instruction entry per iteration so that core simulators have the
instruction information to go along with each load and store, while cache
simulators can ignore these "no-fetch" entries and avoid incorrectly
inflating instruction fetch statistics.

Offline traces guarantee that a branch target instruction entry in a
trace must immediately follow the branch instruction with no intervening
thread switch.  This allows a core simulator to identify the target of a
branch by looking at the subsequent trace entry.

Traces include scheduling markers providing the timestamp and hardware
thread identifier on each thread transition, allowing a simulator to more
closely match the actual hardware if so desired.

Traces also include markers indicating disruptions in user mode control
flow such as signal handler entry and exit.

A final feature that aids core simulators is the pair of interfaces
module_mapper_t::get_loaded_modules() and
module_mapper_t::find_mapped_trace_address(), which facilitate reading the raw
bytes for each instruction in order to obtain the opcode and full operand
information.

****************************************************************************
\section sec_drcachesim_extend Extending the Simulator

The \p drcachesim tool was designed to be extensible, allowing users to
easily model different caching devices, implement different models, and
gather custom statistics.

To model different caching devices, subclass the \p simulator_t,
caching_device_t, caching_device_block_t, caching_device_stats_t classes.

To implement a different cache model, subclass the \p cache_t class and
override the \p request(), \p access_update(), and/or \p
replace_which_way() method(s).

Statistics gathering is separated out into the \p caching_device_stats_t
class.  To implement custom statistics, subclass \p caching_device_stats_t
and override the \p access(), \p child_access(), \p flush(), and/or
\p print_stats() methods.

****************************************************************************
\section sec_drcachesim_tracer Customizing the Tracer

The tracer supports customization for special-purpose i/o via
drmemtrace_replace_file_ops(), allowing traces to be written to locations
not supported by simple UNIX file operations.  One option for using this
function is to create a new client which links with the provided
drmemtrace_static library, includes the \p drmemtrace/drmemtrace.h header via:

\code
use_DynamoRIO_drmemtrace_tracer(mytool)
\endcode

And includes its own dr_client_main() which calls
drmemtrace_client_main().

The tracer also supports storing custom data with each module (i.e.,
library or executable) such as a build identifier via
drmemtrace_custom_module_data().  The custom data may be retrieved by
creating a custom offline trace post-processor and using the #module_mapper_t
class.

****************************************************************************
\section sec_drcachesim_newtool Creating New Analysis Tools

\p drcachesim provides a \p drmemtrace analysis tool framework to make it
easy to create new trace analysis tools.  A new tool should subclass
#analysis_tool_t.  Two key functions should be overridden:
analysis_tool_t::process_memref(), which operates on a single trace entry,
and analysis_tool_t::print_results(), which is called just once after
processing the entire trace and should present the results of analysis.  In
the default mode of operation, the #analyzer_t class iterates over the
trace and calls the analysis_tool_t::process_memref() function of each
tool.  An alternative mode is supported which exposes the iterator and
allows a separate control infrastructure to be built.

Each trace entry is of type #memref_t and represents one instruction or
data reference or a metadata operation such as a thread exit or marker.
There are built-in scheduling markers providing the timestamp and cpu
identifier on each thread transition.  Other built-in markers indicate
disruptions in user mode control flow such as signal handler entry and
exit.

CMake support is provided for including the headers and linking the
libraries of the \p drmemtrace framework.  A new CMake function is defined
in the DynamoRIO package which sets the include directory for using the \p
drmemtrace/ headers:

\code
use_DynamoRIO_drmemtrace(mytool)
\endcode

The \p drmemtrace_analyzer library exported by the DynamoRIO package is the
main library to link when building a new tool.  The tools described above
are also exported as the libraries \p drmemtrace_basic_counts, \p drmemtrace_view,
\p drmemtrace_opcode_mix, \p drmemtrace_histogram, \p drmemtrace_reuse_distance, \p
drmemtrace_reuse_time, and \p drmemtrace_simulator and can be created using
the basic_counts_tool_create(), opcode_mix_tool_create(), histogram_tool_create(),
reuse_distance_tool_create(), reuse_time_tool_create(), view_tool_create(),
cache_simulator_create(), and tlb_simulator_create() functions.

****************************************************************************
\section sec_drcachesim_ops Simulator Parameters

\p drcachesim's behavior can be controlled through options passed after the
\p -c \p drcachesim but prior to the "--" delimiter on the command line:

\code
$ bin64/drrun -t drcachesim <options> <to> <drcachesim> -- /path/to/target/app <args> <for> <app>
\endcode

Boolean options can be disabled using a "-no_" prefix.

The parameters available are described below:

REPLACEME_WITH_OPTION_LIST


****************************************************************************
\section sec_drcachesim_limit Current Limitations

The \p drcachesim tool is a work in progress.  We welcome contributions in
these areas of missing functionality:

- Cache coherence (https://github.com/DynamoRIO/dynamorio/issues/1726)
- Multi-process online application simulation on Windows (https://github.com/DynamoRIO/dynamorio/issues/1727)
- Arbitrary cache hierarchy support via an input config file
  (https://github.com/DynamoRIO/dynamorio/issues/1715)
- Offline traces do not currently accurately record instruction fetches in
  dynamically generated code (https://github.com/DynamoRIO/dynamorio/issues/2062).
  All data references are included, but instruction fetches may be skipped.
  This problem is limited to offline traces.
- Application phase marking is not yet implemented
  (https://github.com/DynamoRIO/dynamorio/issues/2478).

****************************************************************************
\section sec_drcachesim_cmp Comparison to Other Simulators

\p drcachesim is one of the few simulators to support multiple processes.
This feature requires an out-of-process simulator and inter-process
communication.  A single-process design would incur less overhead.  Thus,
we expect \p drcachesim to pay for its multi-process support with
potentially unfavorable performance versus single-process simulators.

When comparing cache hits, misses, and miss rates across simulators, the
details can vary substantially.  For example, some other simulators (such
as \p cachegrind) do not split memory references that cross cache lines
into multiple hits or misses, while \p drcachesim does split them.
Instructions that reference multiple memory words on the same cache line
(such as \p ldm on ARM) are considered to be single accesses by \p
drcachesim, while other simulators (such as \p cachegrind) may split the
accesses into separate pieces.  A final example involves string loop
instructions on x86.  \p drcachesim considers only the first iteration to
involve an instruction fetch (presenting subsequent iterations as a
"non-fetched instruction" which the simulator ignores: the basic_counts
tool does show these as a separate statistics), while other simulators
(incorrectly) issue a fetch to the instruction cache on every iteration of
the string loop.

*/
